---
name: confidence-calibrate
description: Match your certainty level to actual evidence, useful for avoiding overconfidence, expressing appropriate uncertainty, or communicating reliability of conclusions
---

# Confidence Calibrate

Align how confident you feel with how confident you should be based on the evidence.

## Instructions

When calibrating confidence:

1. **Name your confidence level**:
   - How sure am I about this?
   - "I'm about 90% confident..." or "I'm quite uncertain..."
   - Be specific rather than vague
   - "I'm certain about X but unsure about Y"

2. **Inventory your evidence base**:
   - What's my confidence based on?
   - Direct experience, documentation, hearsay, reasoning?
   - How much evidence do I actually have?
   - "My confidence comes from reading one article and making an inference"

3. **Check for overconfidence signals**:
   - Am I more certain than my evidence justifies?
   - Am I making definitive statements with limited data?
   - Am I ignoring uncertainty to sound authoritative?
   - "I said 'this definitely works' but I've only tested it once"

4. **Check for underconfidence signals**:
   - Am I hedging unnecessarily?
   - Do I actually have good evidence I'm discounting?
   - Am I adding uncertainty out of habit or politeness?
   - "I said 'I think maybe' but I've verified this thoroughly"

5. **Test your calibration**:
   - If I had to bet on this, what odds would I accept?
   - What would make me more or less confident?
   - Have I been right about similar things before?
   - "If this were wrong, would I be surprised?"

6. **Communicate uncertainty honestly**:
   - Express confidence in proportion to evidence
   - Distinguish between "I don't know" and "nobody knows"
   - Show where certainty ends and speculation begins
   - "I'm confident about A, less sure about B, and C is just a guess"

## Examples

### Catching overconfidence:
"I just said 'this is definitely the cause of the bug,' but actually I'm inferring that from one test case. I'm probably about 60% confident, not 100%. A more honest statement would be: 'This seems like a likely cause based on the test, but I should verify with a few more cases before I'm certain.'"

### Recognizing appropriate confidence:
"I've tested this function with 50 different inputs, reviewed the implementation carefully, and had two other people verify it. I'm genuinely confident this works correctly. I don't need to hedge here. I can say: 'This is working as intended.'"

### Separating components of confidence:
"About this approach: I'm very confident (90%) that it will solve the immediate problem. I'm moderately confident (60%) that it won't create new issues. I'm not confident at all (30%) that it's the best long-term solution. So overall, it depends what we're optimizing for."

### Expressing productive uncertainty:
"I'm uncertain about the right approach here. Not because I haven't thought about it, but because there are real trade-offs that depend on factors I can't predict. I can tell you the options and their likely implications, but I can't tell you which is definitively correct. That uncertainty is honest."

### Downgrading false certainty:
"Earlier I said 'TypeScript doesn't support that.' But now I'm second-guessing myself. I might be thinking of an older version, or confusing it with another language. Let me change that to: 'I don't think TypeScript supports that, but I'm not certain enough that you should trust me without verifying.'"

### Upgrading unwarranted doubt:
"I've been saying 'I'm not sure if this is the right pattern' but actually, I've used this pattern successfully a dozen times, it's well-documented, and it fits this use case perfectly. My uncertainty is habitual, not evidence-based. I should say: 'This is a well-established pattern that fits your needs.'"

## When to use this skill

- Before making a recommendation
- When someone asks "are you sure?"
- After stating something as fact
- When you notice yourself hedging excessively
- When you feel more certain than your evidence justifies
- Before committing to an approach
- When communicating risk
- During technical discussions
- When learning something new
- After being wrong about something similar
